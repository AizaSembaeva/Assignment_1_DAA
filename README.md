Assignment 1 â€“ Divide and Conquer Algorithms
Introduction

This project implements and analyzes classic divide-and-conquer algorithms, focusing on MergeSort, QuickSort, Deterministic Select (Median-of-Medians), and Closest Pair of Points (2D).

The main goals were to:

Ensure safe recursion and control of recursion depth.

Collect metrics including execution time, number of comparisons, memory allocations, and recursion depth.

Compare theoretical predictions from Master Theorem and Akraâ€“Bazzi intuition with experimental results.

Benchmark linear selection against Javaâ€™s built-in Arrays.sort() for performance evaluation.

1. Architecture Notes

Recursion Depth Control

MergeSort: Recursion depth is logarithmic; small arrays handled by insertion sort.

QuickSort: Recursion on smaller partition, iterative on larger; depth â‰ˆ O(log n).

Deterministic Select: Recurse only into smaller partition; depth remains low.

Closest Pair: Recursive halving; strip-based checks done iteratively.

Allocation Control

MergeSort: Reuses a single merge buffer.

QuickSort & Select: In-place partitioning with minimal allocations.

Closest Pair: Allocates only temporary arrays for strip/y-sorting.

2. Recurrence Analysis

MergeSort

ğ‘‡
(
ğ‘›
)
=
2
ğ‘‡
(
ğ‘›
2
)
+
Î˜
(
ğ‘›
)
=
Î˜
(
ğ‘›
log
â¡
ğ‘›
)
T(n)=2T(
2
n
â€‹

)+Î˜(n)=Î˜(nlogn)

Recursion depth = O(log n).

QuickSort (random pivot)

ğ‘‡
(
ğ‘›
)
=
ğ‘‡
(
ğ‘˜
)
+
ğ‘‡
(
ğ‘›
âˆ’
ğ‘˜
âˆ’
1
)
+
Î˜
(
ğ‘›
)
,
ğ¸
[
ğ‘˜
]
â‰ˆ
ğ‘›
2
T(n)=T(k)+T(nâˆ’kâˆ’1)+Î˜(n),E[k]â‰ˆ
2
n
â€‹


Expected runtime Î˜(n log n), recursion depth â‰ˆ 2 logâ‚‚n.

Deterministic Select

ğ‘‡
(
ğ‘›
)
=
ğ‘‡
(
ğ‘›
5
)
+
ğ‘‡
(
7
ğ‘›
10
)
+
Î˜
(
ğ‘›
)
=
Î˜
(
ğ‘›
)
T(n)=T(
5
n
â€‹

)+T(
10
7n
â€‹

)+Î˜(n)=Î˜(n)

Linear runtime, recursion depth small.

Closest Pair

ğ‘‡
(
ğ‘›
)
=
2
ğ‘‡
(
ğ‘›
2
)
+
Î˜
(
ğ‘›
)
=
Î˜
(
ğ‘›
log
â¡
ğ‘›
)
T(n)=2T(
2
n
â€‹

)+Î˜(n)=Î˜(nlogn)

Depth = O(log n), strip check adds only constant factor.

3. Plots
   3.1 Time vs Input Size (MergeSort & QuickSort)

![Time vs n](graphs/1_graph.png)

MergeSort: grows as Î˜(n log n), stable across input cases.

QuickSort: average Î˜(n log n), but faster on random input, slower for sorted/reversed due to partition imbalance.

3.2 Recursion Depth vs Input Size

![Recursion Depth](graphs/2_graph.png)

MergeSort: logarithmic depth growth.

QuickSort: bounded near constant (due to iterative handling of larger partition).

Select: very shallow recursion, depth â‰¤ 5 for tested n.

3.3 Throughput vs Input Size (Select vs Arrays.sort)

![Throughput](graphs/3_graph.png)

Arrays.sort: high throughput at n=1000 but drops steeply for larger sizes.

Deterministic Select: lower at small n, but scales better at larger n.

Confirms Selectâ€™s linear scaling advantage.

3.4 Comparisons vs Input Size

![Comparisons](graphs/4_graph.png)

MergeSort: ~n log n comparisons.

QuickSort: slightly higher comparisons due to pivot randomness.

Select: linear comparisons, much smaller growth than sorting.

4. Alignment Between Theory and Measurements

MergeSort: Matches Î˜(n log n) in time, depth, comparisons.

QuickSort: Average case confirmed, small deviations from pivot randomness.

Select: Linear growth validated; throughput confirms expected scaling.

Closest Pair: Follows Î˜(n log n) trend, with log recursion depth.

5. Summary

All algorithms were implemented according to divide-and-conquer principles.

Recursion depth was controlled, allocations minimized.

Metrics collection and JMH benchmarking validated theoretical predictions.

Experimental results align with Master Theorem and Akraâ€“Bazzi analysis.